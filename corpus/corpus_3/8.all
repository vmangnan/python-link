#!/usr/local/bin/pythonw
# -*- coding: utf-8 -*-

import re, string, htmlentitydefs

def ltuple2ul(l) :
  s = ''
  for t in l :
    i = ''
    for e in t :
      i += '%s '%(e)
    s += '<li>%s</li>'%(i)
  return '<ul>%s</ul>'%s

def list2ul(l) :
  s = ''
  for e in l :
    s += '<li>%s</li>'%(e)
  return '<ul>%s</ul>'%s

def dict2ul(d) :
  s = ''
  for k,e in d.iteritems() :
    s += '<li>%s :: %s</li>'%(str(k),str(e))
  return '<ul>%s</ul>'%s

def dict_count(d, k) :
  if(d.has_key(k)) :
    d[k] += 1
  else :
    d[k] = 1

def read_file(path_file) :
  f = open(path_file, 'r')
  s = f.read()
  f.close()
  return s

def write_file(path_file, s) :
  f = open(path_file, 'w')
  f.write(s)
  f.close()

def source2encoding(s) :
  default_encoding = 'iso-8859-1'
  pattern_detect_encoding = u'<meta http-equiv=["\']content-Type["\'][ \n\r]*content=["\']text/html; ?charset=(.*?)["\']'
  pattern_compiled = re.compile(pattern_detect_encoding, re.I)
  match_charset = re.search(pattern_compiled, s)
  if match_charset :
    encoding = string.lower(match_charset.group(1))
    print 'detected charset ::', encoding.encode('utf-8')
  else :
    encoding = default_encoding
    print 'undetected charset, use default encoding ::', default_encoding
  return encoding

def color_string(s_unicode, substring, color) :
  print 'color string : %s'%(substring.encode('utf-8'))
  pattern1 = re.compile(u'%s'%(substring), re.I | re.M)
  replace = u'<span style="color:%s; background-color:grey;">%s</span>'%(color, substring)
  output = pattern1.sub(replace, s_unicode)
  return output

def clean_unicode_html(s_unicode) :
  clean_html = re.sub(u'&nbsp;', ' ', s_unicode)
  clean_html = re.sub(u'[\s]+', u' ', clean_html)

  pattern1 = re.compile(u'<script.+?</script>', re.I | re.M)
  clean_html = pattern1.sub(u'', clean_html)

  pattern2 = re.compile(u'<!\-\-.+?\-\->', re.M)
  clean_html = pattern2.sub(u'', clean_html)

  pattern3 = re.compile(u'<select.+?</select>', re.I | re.M)
  clean_html = pattern3.sub(u'', clean_html)

  pattern4 = re.compile(u'<style.+?</style>', re.I | re.M)
  clean_html = pattern4.sub(u'', clean_html)

  clean_html = re.sub(u'(?:&gt;|&lt;)', u' ', clean_html)

  pattern5 = re.compile(u'[\s]*</*[^>]+/*>[\s]*', re.I | re.M)
  clean_html = pattern5.sub(u' # ', clean_html)

  pattern6 = re.compile(u'\s[#\s]+', re.I | re.M)
  clean_html = pattern6.sub(u' # ', clean_html)
  
  return clean_html

def decode_html_entities(s_unicode) :
  html = re.sub(u'&#([0-9]+);', replace_num_entities, s_unicode)
  pattern = re.compile(u'&([a-z]+);', re.I)
  html = pattern.sub(replace_alpha_entities, html)
  return html

def replace_num_entities(matchobj_unicode) :
  if int(matchobj_unicode.group(1)) in range(65535):
    return unichr(int(matchobj_unicode.group(1)))
  else:
    return u'&#%s;'%(matchobj_unicode.group(1))

def replace_alpha_entities(matchobj_unicode) :
  k = matchobj_unicode.group(1)
  if not htmlentitydefs.entitydefs.has_key(k) :
    if k.isupper() :
      k = string.lower(matchobj_unicode.group(1))
      if not htmlentitydefs.entitydefs.has_key(cle) :
        return ''
    else :
      return ''
  if len(htmlentitydefs.entitydefs[k]) == 1 :
    car = htmlentitydefs.entitydefs[k]
    return unicode(car, 'iso-8859-1')
  else :
    str_code = htmlentitydefs.entitydefs[k].strip(u'&#;')
    return unichr(int(str_code))

#!/usr/local/bin/pythonw
# -*- coding: utf-8 -*-



#### mes imports #####

import re
import os
import sys
import string
import re, string, htmlentitydefs

import tool_ltal as tl


#### Mes fonctions ######

def read_file(path_file) :
  f = open(path_file, 'r')
  s = f.read()
  f.close()
  return s
  
def source2encoding(s) :
  default_encoding = 'iso-8859-1'
  pattern_detect_encoding = u'<meta http-equiv=["\']content-Type["\'][ \n\r]*content=["\']text/html; ?charset=(.*?)["\']'
  pattern_compiled = re.compile(pattern_detect_encoding, re.I)
  match_charset = re.search(pattern_compiled, s)
  if match_charset :
    encoding = string.lower(match_charset.group(1))
    print 'detected charset ::', encoding.encode('utf-8')
  else :
    encoding = default_encoding
    print 'undetected charset, use default encoding ::', default_encoding
  return encoding

def clean_unicode_html(s_unicode) :
  clean_html = re.sub(u'&nbsp;', ' ', s_unicode)
  clean_html = re.sub(u'[\s]+', u' ', clean_html)

  pattern1 = re.compile(u'<script.+?</script>', re.I | re.M)
  clean_html = pattern1.sub(u'', clean_html)

  pattern2 = re.compile(u'<!\-\-.+?\-\->', re.M)
  clean_html = pattern2.sub(u'', clean_html)

  pattern3 = re.compile(u'<select.+?</select>', re.I | re.M)
  clean_html = pattern3.sub(u'', clean_html)

  pattern4 = re.compile(u'<style.+?</style>', re.I | re.M)
  clean_html = pattern4.sub(u'', clean_html)

  clean_html = re.sub(u'(?:&gt;|&lt;)', u' ', clean_html)

  pattern5 = re.compile(u'[\s]*</*[^>]+/*>[\s]*', re.I | re.M)
  clean_html = pattern5.sub(u' # ', clean_html)

  pattern6 = re.compile(u'\s[#\s]+', re.I | re.M)
  clean_html = pattern6.sub(u' # ', clean_html)
  
  return clean_html



def replace_alpha_entities(matchobj_unicode) :
  k = matchobj_unicode.group(1)
  if not htmlentitydefs.entitydefs.has_key(k) :
    if k.isupper() :
      k = string.lower(matchobj_unicode.group(1))
      if not htmlentitydefs.entitydefs.has_key(cle) :
        return ''
    else :
      return ''
  if len(htmlentitydefs.entitydefs[k]) == 1 :
    car = htmlentitydefs.entitydefs[k]
    return unicode(car, 'iso-8859-1')
  else :
    str_code = htmlentitydefs.entitydefs[k].strip(u'&#;')
    return unichr(int(str_code))



def replace_num_entities(matchobj_unicode) :
  if int(matchobj_unicode.group(1)) in range(65535):
    return unichr(int(matchobj_unicode.group(1)))
  else:
    return u'&#%s;'%(matchobj_unicode.group(1))


def decode_html_entities(s_unicode) :
  html = re.sub(u'&#([0-9]+);', replace_num_entities, s_unicode)
  pattern = re.compile(u'&([a-z]+);', re.I)
  html = pattern.sub(replace_alpha_entities, html)
  return html

def get_list_words(html_unicode) :
  pattern_word = u'[\w]+'
  pattern_word_compiled = re.compile(pattern_word,re.U)
  list_words = pattern_word_compiled.findall(html_unicode)
  return list_words

def traite_list(ma_list):
	for elt in (ma_list):
		print elt.encode('utf-8')
	


def dict_count(d, k) :
  if(d.has_key(k)) :
    d[k] += 1
  else :
    d[k] = 1

def list_words2dict_effectif(list_words_unicode) :
  dict_effectif = {}
  for graphie in list_words_unicode :
    tl.dict_count(dict_effectif, graphie)
  return dict_effectif

def dict_effectif2distrib_zipf(dict_effectif) :
  l = []
  for graphie,effectif in dict_effectif.iteritems() :
    l.append((effectif,graphie))
  l = sorted(l, reverse=True)
  return l

###Fonctions tp3###



def trigram(chaine) :
	trigram = u'\w{3,3}'
	trigram_compiled = re.compile(trigram,re.U)
	l = trigram_compiled.findall(chaine)
	return l

def get_ngram(liste,n):
	d={}
	len_w=len(liste)
	for i in xrange(len_w-n):
		lngram=liste[i]
		
		if lngram not in d :
			d[lngram]=0
		d[lngram]+=1
	return d
	
	
def comparaison(doc,ress):
	somme_commune = 0
	
	for graphie, effectif in doc:
		for graph, effect in ress:
			if graphie == graph:
				somme_commune += 1
	
	res = doc.length / somme_commune
	
	return 
	

def analyseur_trigramme(doc):
	
	
	## Traitement document ##	

	doc_encoding = source2encoding(doc)

	doc_unicode = unicode(doc,doc_encoding)

	doc_trait = clean_unicode_html(doc_unicode)

	doc_decode = decode_html_entities(doc_trait)
	
	liste_mot_doc = get_list_words(doc_decode)

	liste_gram = trigram(doc_decode.encode('utf-8'))

	doc_gram = get_ngram(liste_gram,3)


 ## Traitement ressource ##

  for ress in ressource:
		
    ress = read_file(ress)
		
    ress_encoding = source2encoding(ress)

    ressource_unicode = unicode(ress,ress_encoding)

    ress_trait = clean_unicode_html(ress_unicode)

    ress_decode = decode_html_entities(ress_trait)
	
    liste_mot_ress = get_list_words(ress_decode.encode('utf-8'))

    liste_gram_ress = trigram(ress_decode.encode('utf-8'))

	doc_gram_ress = get_ngram(liste_gram_ress,3)


	
  tx = comparaison(zipf, zipf_ress)
	
	return doc_gram

def analyseur_zipf(doc, ressources):
	
	## Traitement document ##
	
  doc_encoding = source2encoding(doc)

  doc_unicode = unicode(doc,doc_encoding)

  doc_trait = clean_unicode_html(doc_unicode)

  doc_decode = decode_html_entities(doc_trait)
	
  liste_mot_doc = get_list_words(doc_decode.encode('utf-8'))

  dico = list_words2dict_effectif(liste_mot_doc)

  zipf = dict_effectif2distrib_zipf(dico)
  
  
  ## Traitement ressource ##


  for ress in ressource:
		
    ress = read_file(ress)
		
    ress_encoding = source2encoding(ress)

    ressource_unicode = unicode(ress,ress_encoding)

    ress_trait = clean_unicode_html(ress_unicode)

    ress_decode = decode_html_entities(ress_trait)
	
    liste_mot_ress = get_list_words(ress_decode.encode('utf-8'))

    dico_ress = list_words2dict_effectif(liste_mot_ress)

    zipf_ress = dict_effectif2distrib_zipf(dico_ress)


	
  tx = comparaison(zipf, zipf_ress)
	
  return zipf


  

###### Ma cha√Æne de traitement #####


path_file = 'doc.html'

ressource = ('corpus\celex_IP-09-1.de','corpus\celex_IP-09-1.en','corpus\celex_IP-09-1.fr','corpus\celex_IP-09-celex_IP-09-1.sk','corpus\celex_IP-09-2.de','corpus\celex_IP-09-2.en','corpus\celex_IP-09-2.fr')

chaine = read_file(path_file)

liste = trigram(chaine)

l = get_ngram(liste,3)

res = analyseur_trigramme(chaine)

res2 = analyseur_zipf(chaine,ressource)

print res2
