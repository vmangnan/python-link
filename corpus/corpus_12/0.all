#!/usr/local/bin/pythonw
# -*- coding: utf-8 -*-

import re, string, htmlentitydefs

def ltuple2ul(l) :
  s = ''
  for t in l :
    i = ''
    for e in t :
      i += '%s '%(e)
    s += '<li>%s</li>'%(i)
  return '<ul>%s</ul>'%s

def list2ul(l) :
  s = ''
  for e in l :
    s += '<li>%s</li>'%(e)
  return '<ul>%s</ul>'%s

def dict2ul(d) :
  s = ''
  for k,e in d.iteritems() :
    s += '<li>%s :: %s</li>'%(str(k),str(e))
  return '<ul>%s</ul>'%s

def dict_count(d, k) :
  if(d.has_key(k)) :
    d[k] += 1
  else :
    d[k] = 1

def read_file(path_file) :
  f = open(path_file, 'r')
  s = f.read()
  f.close()
  return s

def write_file(path_file, s) :
  f = open(path_file, 'w')
  f.write(s)
  f.close()

def source2encoding(s) :
  default_encoding = 'iso-8859-1'
  pattern_detect_encoding = u'<meta http-equiv=["\']content-Type["\'][ \n\r]*content=["\']text/html; ?charset=(.*?)["\']'
  pattern_compiled = re.compile(pattern_detect_encoding, re.I)
  match_charset = re.search(pattern_compiled, s)
  if match_charset :
    encoding = string.lower(match_charset.group(1))
    #print 'detected charset ::', encoding.encode('utf-8')
  else :
    encoding = default_encoding
    #print 'undetected charset, use default encoding ::', default_encoding
  return encoding

def color_string(s_unicode, substring, color) :
  #print 'color string : %s'%(substring.encode('utf-8'))
  pattern1 = re.compile(u'%s'%(substring), re.I | re.M)
  replace = u'<span style="color:%s; background-color:grey;">%s</span>'%(color, substring)
  output = pattern1.sub(replace, s_unicode)
  return output

def clean_unicode_html(s_unicode) :
  clean_html = re.sub(u'&nbsp;', ' ', s_unicode)
  clean_html = re.sub(u'[\s]+', u' ', clean_html)

  pattern1 = re.compile(u'<script.+?</script>', re.I | re.M)
  clean_html = pattern1.sub(u'', clean_html)

  pattern2 = re.compile(u'<!\-\-.+?\-\->', re.M)
  clean_html = pattern2.sub(u'', clean_html)

  pattern3 = re.compile(u'<select.+?</select>', re.I | re.M)
  clean_html = pattern3.sub(u'', clean_html)

  pattern4 = re.compile(u'<style.+?</style>', re.I | re.M)
  clean_html = pattern4.sub(u'', clean_html)

  clean_html = re.sub(u'(?:&gt;|&lt;)', u' ', clean_html)

  pattern5 = re.compile(u'[\s]*</*[^>]+/*>[\s]*', re.I | re.M)
  clean_html = pattern5.sub(u' # ', clean_html)

  pattern6 = re.compile(u'\s[#\s]+', re.I | re.M)
  clean_html = pattern6.sub(u' # ', clean_html)
  
  return clean_html

def decode_html_entities(s_unicode) :
  html = re.sub(u'&#([0-9]+);', replace_num_entities, s_unicode)
  pattern = re.compile(u'&([a-z]+);', re.I)
  html = pattern.sub(replace_alpha_entities, html)
  return html

def replace_num_entities(matchobj_unicode) :
  if int(matchobj_unicode.group(1)) in range(65535):
    return unichr(int(matchobj_unicode.group(1)))
  else:
    return u'&#%s;'%(matchobj_unicode.group(1))

def replace_alpha_entities(matchobj_unicode) :
  k = matchobj_unicode.group(1)
  if not htmlentitydefs.entitydefs.has_key(k) :
    if k.isupper() :
      k = string.lower(matchobj_unicode.group(1))
      if not htmlentitydefs.entitydefs.has_key(cle) :
        return ''
    else :
      return ''
  if len(htmlentitydefs.entitydefs[k]) == 1 :
    car = htmlentitydefs.entitydefs[k]
    return unicode(car, 'iso-8859-1')
  else :
    str_code = htmlentitydefs.entitydefs[k].strip(u'&#;')
    return unichr(int(str_code))

#!/usr/local/bin/pythonw
# -*- coding: utf-8 -*-

import re
import os
import sys
import csv
import glob
import matplotlib.pyplot as pyplot

import tool_ltal as tl

import operator


# Chaqu'une des 4 prochaines fonctions a été conçu pour repondre aux questions du TP


def question1_2(listlang):
  """Cette fonction prend en entré une liste de langues presents dans le corpus, ou la chaine de charactere 'all' pour faire les graphs de distribution zipf demandés"""

  
  colors=['b-','g-','r-','c-','m-','y-','k-']
  i=0
  j=-1
  l=[]


  if listlang=='all':
    listlang=['De','El','En','Fi','Fr','Ru','Zh'] #Cette partie est necessaire sinon la boucle va chercher des fichiers dans des dossiers 'a' 'l' etc...
    for lang in listlang:
      
      for fich in glob.glob("Corpus/%s/*.htm"%(lang)):
        f=prepare_file(fich)
        l+=get_list_words(f)
      dic=list_words2dict_effectif(l)
      draw_graph(range(0,len(d)),d,'all','Output/ZipfGlobal.png',colors[i])
      i+=1
    
  else:
    for lang in listlang:
      
      for fich in glob.glob("Corpus de Texte LTAL/%s/*.htm"%(lang)):
        f=prepare_file(fich)
        l+=get_list_words(f)
      dic=list_words2dict_effectif(l)
      d=dict_effectif2distrib_zipf(dic)
      draw_graph(range(0,len(d)),d,lang,'Output/%s Zipf.png' %(lang),'b-')
      i+=1

      for x in dic:
        x.encode('utf-8')
        pyplot.figure('%s nuage'%(lang))
        pyplot.plot(len (x),dic[x],'.')
        pyplot.xlabel('Longueur')
        pyplot.ylabel('Effectif')
          
      pyplot.savefig('Output/%s Zipf1.png' %(lang))

    
def question3():

  #Recuperation de la liste de la distribution zipf des mots dans le corpus, ici seul les textes en chinois sont pris en compte
  #On utlise la fonction "list" pour convertir la chaine de caracteres genere par la fonction prepare file, en liste ou les elements
  #sont les caracteres de f.
  
  l=[]
  for fich in glob.glob("Corpus de Texte LTAL/Zh/*.htm"):
    f=prepare_file(fich)
    l+=list(f)

  dic=list_words2dict_effectif(l)
  d=dict_effectif2distrib_zipf(dic)

  #Impression des resultats dans une graph
  
  draw_graph(range(0,len(d)),d,'Zh','Output/Question3.png','r-')



def question4(listlang):
  #Utilisation de la module 'csv' pour generer un fichier tableur contenant les resultats
  l=[]
  
  tab=open('question4.csv','wb')
  c=csv.writer(tab)
  c.writerow(['','Nombre de Mots','Nombre de mots differents','Rapport nbmots/motsdiff'])
  
  for lang in listlang:
    
    for fich in glob.glob("Corpus de Texte LTAL/%s/*.htm"%(lang)):
      f=prepare_file(fich)
      l+=get_list_words(f)

    dic=list_words2dict_effectif(l)
    d=dict_effectif2distrib_zipf(dic)
    
    c.writerow([lang,len(l),len(dic),float(float(len(l))/float(len(dic)))])
    
  tab.close()
  

def question5(listlang):
  #Cette fonction marche et genere bien le dictionnaire contenant les ngram répétés dans le texte, et devrait retourner un fichier html coloré
  #Mais elle retourne une erreur que je n'arrive pas a resoudre:

  
  #    Traceback (most recent call last):
  #    File "<pyshell#0>", line 1, in <module>
  #      question5(['En'])
  #    File "C:\Users\Stu\Desktop\Final\tp_1_2.py", line 114, in question5
  #      pattern1 = re.compile(u'%s'%(mot), re.I | re.M)
  #    File "C:\Python27\lib\re.py", line 190, in compile
  #      return _compile(pattern, flags)
  #    File "C:\Python27\lib\re.py", line 242, in _compile
  #     raise error, v # invalid expression
  # error: unexpected end of regular expression

  
  for lang in listlang:
    i=1
    for fich in glob.glob("Corpus de Texte LTAL/%s/*.htm" %lang):
      f=prepare_file(fich)
      d=n_gram(f)
      for ngram in d.keys():
          for mot in ngram:
            pattern1 = re.compile(u'%s'%(mot), re.I | re.M)
            replace = u'<span style="color:AA2222; background-color:grey;">%s</span>' %(mot)
            output = pattern1.sub(replace, unicode(tl.read_file(fich),'utf-8'))

      File=open("Output/%s/%s%s.html" %(lang,lang,i),"w")
      File.write(f.encode('utf-8'))
      File.close()
      
        

def get_header_html() :
  s = '''
  <html>
    <head>
      <meta http-equiv="Content-Type"
            content="text/html; charset=utf-8">
      <title>Titre</title>
    </head>
    <body>
  '''
  return s

def get_footer_html() :
  s = '''
    </body>
  </html>
  '''
  return s

def prepare_file(path_file) :
  src_html = tl.read_file(path_file)
  encoding_detected = tl.source2encoding(src_html)
  src_html_unicode = unicode(src_html,encoding_detected)
  src_html_unicode = tl.clean_unicode_html(src_html_unicode)
  src_html_unicode = tl.decode_html_entities(src_html_unicode)
  return src_html_unicode

def extract_title(html_unicode) :
  pattcomp = re.compile(u'<title>(.+)<\/title>', re.I)
  trouv_titre = re.search(pattcomp, html_unicode)
  if trouv_titre:
    return trouv_titre.group(1)
  return ''

def get_list_words(html_unicode) :
  pattern_word = u'[^ \d \s . ? , ! : ; / # " ( ) \ £ $ € | * = + { } ² < > ° @ • _ % -]+'
  
  pattern_word_compiled = re.compile(pattern_word)
  list_words = pattern_word_compiled.findall(html_unicode)
  return list_words

def list_words2dict_effectif(list_words_unicode) :
  dict_effectif = {}
  for graphie in list_words_unicode :
    tl.dict_count(dict_effectif, graphie)
  return dict_effectif

def dict_effectif2distrib_zipf(dict_effectif) :
  l = []
  for graphie,effectif in dict_effectif.iteritems() :
    l.append(effectif)
  l = sorted(l, reverse=True)
  return l

def draw_graph(x,y,i,OutPut,color):
#  pyplot.figure(i)
  pyplot.plot(x,y,color)
  pyplot.xlabel('log(rang)')
  pyplot.ylabel('log(eff)')
  pyplot.loglog()
  pyplot.savefig(OutPut)


def main(path_file) :
  src_html_brut = unicode(tl.read_file(path_file),'utf-8')
  src_html_unicode = prepare_file(path_file)
  title_detected = extract_title(src_html_brut)
  if title_detected != '' :
    str_t = '<p>%s</p>'%(title_detected)
  else :
    str_t = '<p>nop</p>'

  l = get_list_words(src_html_unicode)
  d = list_words2dict_effectif(l)
  z = dict_effectif2distrib_zipf(d)

  it = d.items()
  def cmpval(x,y) :
    return y[1] - x[1]
  it.sort(cmpval)

  str_z = tl.ltuple2ul(it)

  str_h = get_header_html()
  str_f = get_footer_html()

  output_zipf = '%s %s %s %s'%(str_h, str_t, str_z, str_f)

  s_color = 'chaine de '
  s_color = unicode(s_color,'utf-8')
  src_html_unicode = unicode(tl.read_file(path_file),'utf-8')
  output_color = tl.color_string(src_html_unicode, s_color,'#AA2222')
  
  p=open("final.htm","w")
  p.write(output_color.encode('utf-8'))
  p.close()
  
  
  return output_zipf,output_color

  if __name__=='__main__' :
    path_file = sys.argv[1]
    outputzipf, outputcolor = main(path_file)

    outputzipf_utf8 = outputzipf.encode('utf-8')
    tl.write_file('out_zipf.html',outputzipf_utf8)

    outputcolor_utf8 = outputcolor.encode('utf-8')
    tl.write_file('color.html',outputcolor_utf8)

def cutBlocs(s):
  l=[]
  tmp=""
  pattern=re.compile(u"[\s]+")
  for char in s:
    if char=="#":
      if tmp==pattern:
        l=l
      else:
        l=l+[tmp]
      tmp=""
    else :
      tmp=tmp+char
  return l

def get_ngram(l,n):
  d={}
  len_w=len(l)
  for i in xrange(len_w):
    lngram=l[i:i+n]
    ngram=tuple(lngram)
    if ngram not in d:
      d[ngram]=0
    d[ngram]+=1
  return d

##def check_continue(d):
##  for t in d:
##    if d[t]>1:
##      return True
##  return False

def fiLter(d):
  filtered={}
  for k,v in d.iteritems():
    if v>1:
      filtered[k]=v
  return filtered


def get_all_ngram(l):
  d={}
  n=2
  b=True
  while b:
    dng=get_ngram(l,n)
    f_dng=fiLter(dng)
    b= not (f_dng=={})
    d.update(f_dng)
    n+=1
  return d

def n_gram(source_unicode):
  end=get_all_ngram(cutBlocs(source_unicode))
  gram=open("ngram.html","w")
  gram.write(str(end))
  gram.close()
  return end


question1_2('all')


exit()




x=raw_input("Quel question, voulez vous lancer ? (1 et 2, 3, 4 ou 5)\n")
if x==str(1) or x==str(2):
  y=raw_input("Sur quels langues ? (de la forme ['De','El','En','Fi','Fr','Ru','Zh'],ou ['all'])\n")
  question1_2(y)

elif x==str(3):
  question3()

elif x==str(4):
  y=raw_input("Sur quels langues ? (de la forme ['De','El','En','Fi','Fr','Ru','Zh']\n")
  question4(y)

elif x==str(5):
  y=raw_input("Sur quels langues ? (de la forme ['De','El','En','Fi','Fr','Ru','Zh']\n")
  question5(y)
